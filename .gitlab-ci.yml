# Web client of the Sensor Management System software developed within
# the Helmholtz DataHub Initiative by GFZ and UFZ.
#
# Copyright (C) 2020-2021
# - Kotyba Alhaj Taha (UFZ, kotyba.alhaj-taha@ufz.de)
# - Wilhelm Becker (GFZ, wilhelm.becker@gfz-potsdam.de)
# - Nils Brinckmann (GFZ, nils.brinckmann@gfz-potsdam.de)
# - Marc Hanisch (GFZ, marc.hanisch@gfz-potsdam.de)
# - Helmholtz Centre for Environmental Research GmbH - UFZ
#   (UFZ, https://www.ufz.de)
# - Helmholtz Centre Potsdam - GFZ German Research Centre for
#   Geosciences (GFZ, https://www.gfz-potsdam.de)
#
# Parts of this program were developed within the context of the
# following publicly funded projects or measures:
# - Helmholtz Earth and Environment DataHub
#   (https://www.helmholtz.de/en/research/earth_and_environment/initiatives/#h51095)
#
# Licensed under the HEESIL, Version 1.0 or - as soon they will be
# approved by the "Community" - subsequent versions of the HEESIL
# (the "Licence").
#
# You may not use this work except in compliance with the Licence.
#
# You may obtain a copy of the Licence at:
# https://gitext.gfz-potsdam.de/software/heesil
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the Licence is distributed on an "AS IS" basis,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied. See the Licence for the specific language governing
# permissions and limitations under the Licence.

stages:
  - build
  - backup
  - deploy

variables:
  GIT_SUBMODULE_STRATEGY: recursive
  ALLOWED_MIME_TYPES: "application/x-abiword,application/x-freearc,application/vnd.amazon.ebook,image/bmp,application/x-bzip,application/x-bzip2,text/csv,application/msword,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/epub+zip,application/gzip,image/gif,text/html,image/vnd.microsoft.icon,text/calendar,image/jpeg,application/json,application/ld+json,application/vnd.oasis.opendocument.presentation,application/vnd.oasis.opendocument.spreadsheet,application/vnd.oasis.opendocument.text,image/png,application/pdf,application/vnd.ms-powerpoint,application/vnd.openxmlformats-officedocument.presentationml.presentation,application/vnd.rar,application/rtf,image/svg+xml,application/x-tar,image/tiff,image/tiff,text/plain,image/webp,application/xhtml+xml,application/vnd.ms-excel,application/vnd.openxmlformats-officedocument.spreadsheetml.sheet,application/xml,application/vnd.mozilla.xul+xml,application/zip,application/x-7z-compressed"

cache:
  paths:
    - frontend/dist

.docker_login_gitlab_registry: &docker_login_gitlab_registry
  - echo "$CI_BUILD_TOKEN" | docker login -u "$CI_REGISTRY_USER" --password-stdin $CI_REGISTRY

.docker_build:
  image: docker:20.10.7
  services:
    - docker:20.10.7-dind
  before_script:
    - *docker_login_gitlab_registry
  tags:
    - docker

build-deploy-image-nginx-gfz-staging:
  stage: build
  extends: .docker_build
  variables:
    CLIENT_ID: ${GFZ_STAGING_OIDC_CLIENT_ID}
  script:
    - |
        docker build --tag "$CI_REGISTRY_IMAGE/nginx:gfz-latest" -f docker/build/nginx/gfz/staging/Dockerfile \
          --build-arg CLIENT_ID_ARG=$CLIENT_ID \
          --build-arg ALLOWED_MIME_TYPES_ARG=$ALLOWED_MIME_TYPES \
          .
    - docker push "$CI_REGISTRY_IMAGE/nginx:gfz-latest"
  cache:
    key: ${CI_COMMIT_REF_SLUG}
    paths:
      - frontend/node_modules
  rules:
    - if: '$CI_PIPELINE_SOURCE == "schedule"'
      when: never
    - if: '$CI_PIPELINE_SOURCE == "pipeline"'
      when: never
    - if: '$CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH'
      when: always
    

build-deploy-image-nginx-gfz-staging-develop:
  stage: build
  extends: .docker_build
  variables:
    NGINX_IMAGE_TAG: "gfz-latest-develop"
  before_script:
    - *docker_login_gitlab_registry
    - apk add --update wget && rm -rf /var/cache/apk/*
  script:
    # Frontend project is passed via CICD var and should be configured with the gitlab repository setup
    - 'wget --header="JOB-TOKEN: $CI_JOB_TOKEN" ${CI_API_V4_URL}/projects/${PROJECT_ID_FRONTEND}/packages/generic/gfz-statics/manual/signed-dist.tar'
    # Use dist folder for multiple distributions
    - mkdir -p dist/manual/
    - tar -xvf signed-dist.tar
    - sha256sum -c dist-sha256sum.txt
    - tar -zxvf dist.tar.gz -C dist/manual --strip-components=1
    # Remove dist tar files of manual version
    - rm signed-dist.tar dist.tar.gz
    # Frontend project is passed via CICD var and should be configured with the gitlab repository setup
    - 'wget --header="JOB-TOKEN: $CI_JOB_TOKEN" ${CI_API_V4_URL}/projects/${PROJECT_ID_FRONTEND}/packages/generic/gfz-statics/latest/signed-dist.tar'
    # Use dist folder for multiple distributions
    - mkdir -p dist/latest/
    - tar -xvf signed-dist.tar
    - sha256sum -c dist-sha256sum.txt
    - tar -zxvf dist.tar.gz -C dist/latest --strip-components=1
    - docker build --tag "$CI_REGISTRY_IMAGE/nginx:gfz-latest-develop" -f docker/build/nginx/gfz/staging-dev/Dockerfile .
    - docker push "$CI_REGISTRY_IMAGE/nginx:$NGINX_IMAGE_TAG"
  rules:
    - if: '$CI_PIPELINE_SOURCE == "schedule"'
      when: never
    # Exclude pipeline source, to prohibit triggering from different repo default branch
    - if: '$CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH && $CI_PIPELINE_SOURCE != "pipeline"'
      when: always
    - if: '$CI_PIPELINE_SOURCE == "pipeline" && $UPSTREAM_DEPLOYMENT_ONLY != "true"'
      when: always


build-deploy-image-nginx-gfz-prod:
  stage: build
  extends: .docker_build
  variables:
    CLIENT_ID: ${GFZ_PROD_OIDC_CLIENT_ID}
  script:
    - |
        docker build --tag "$CI_REGISTRY_IMAGE/nginx:gfz-${CI_COMMIT_TAG:-prod-latest}" -f docker/build/nginx/gfz/prod/Dockerfile \
          --build-arg CLIENT_ID_ARG=$CLIENT_ID \
          --build-arg ALLOWED_MIME_TYPES_ARG=$ALLOWED_MIME_TYPES \
          .
    - docker push "$CI_REGISTRY_IMAGE/nginx:gfz-${CI_COMMIT_TAG:-prod-latest}"
  cache:
    key: ${CI_COMMIT_REF_SLUG}
    paths:
      - frontend/node_modules
  rules:
    - if: '$CI_PIPELINE_SOURCE == "schedule"'
      when: never
    - if: '$CI_PIPELINE_SOURCE == "pipeline"'
      when: never
    - if: '$CI_COMMIT_REF_PROTECTED && $CI_COMMIT_TAG'
      when: always

build-deploy-image-nginx-ufz-staging:
  stage: build
  extends: .docker_build
  script:
    - docker build --tag "$CI_REGISTRY_IMAGE/nginx:ufz-latest" -f docker/build/nginx/ufz/staging/Dockerfile ./docker/build/nginx/ufz/staging/
    - docker push "$CI_REGISTRY_IMAGE/nginx:ufz-latest"
  allow_failure: true
  rules:
    - if: '$CI_PIPELINE_SOURCE == "schedule"'
      when: never
    - if: '$CI_PIPELINE_SOURCE == "pipeline"'
      when: never
    - if: '$CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH'
      when: always

build-deploy-image-vocabulary-gfz-staging:
  stage: build
  extends: .docker_build
  script:
    - |
        docker build --tag "$CI_REGISTRY_IMAGE/vocabulary:gfz-latest" -f sms-cv/docker/gfz/deployment/Dockerfile \
          sms-cv
    - docker push "$CI_REGISTRY_IMAGE/vocabulary:gfz-latest"
  rules:
    - if: '$CI_PIPELINE_SOURCE == "schedule"'
      when: never
    - if: '$CI_PIPELINE_SOURCE == "pipeline"'
      when: never
    - if: '$CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH'
      when: always
    

build-deploy-image-vocabulary-gfz-prod:
  stage: build
  extends: .docker_build
  script:
    - |
        docker build --tag "$CI_REGISTRY_IMAGE/vocabulary:gfz-${CI_COMMIT_TAG:-prod-latest}" -f sms-cv/docker/gfz/deployment/Dockerfile \
          sms-cv
    - docker push "$CI_REGISTRY_IMAGE/vocabulary:gfz-${CI_COMMIT_TAG:-prod-latest}"
  rules:
    - if: '$CI_PIPELINE_SOURCE == "schedule"'
      when: never
    - if: '$CI_PIPELINE_SOURCE == "pipeline"'
      when: never
    - if: '$CI_COMMIT_REF_PROTECTED && $CI_COMMIT_TAG'
      when: always

build-deploy-image-backend-gfz-staging:
  stage: build
  extends: .docker_build
  script:
    - |
        docker build --tag "$CI_REGISTRY_IMAGE/backend:gfz-latest" -f backend/Dockerfile \
          backend
    - docker push "$CI_REGISTRY_IMAGE/backend:gfz-latest"
  rules:
    - if: '$CI_PIPELINE_SOURCE == "schedule"'
      when: never
    - if: '$CI_PIPELINE_SOURCE == "pipeline"'
      when: never
    - if: '$CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH'
      when: always
    

build-deploy-image-backend-gfz-prod:
  stage: build
  extends: .docker_build
  script:
    - |
        docker build --tag "$CI_REGISTRY_IMAGE/backend:gfz-${CI_COMMIT_TAG:-prod-latest}" -f backend/Dockerfile \
          backend
    - docker push "$CI_REGISTRY_IMAGE/backend:gfz-${CI_COMMIT_TAG:-prod-latest}"
  rules:
    - if: '$CI_PIPELINE_SOURCE == "schedule"'
      when: never
    - if: '$CI_PIPELINE_SOURCE == "pipeline"'
      when: never
    - if: '$CI_COMMIT_REF_PROTECTED && $CI_COMMIT_TAG'
      when: always

build-deploy-image-mc-gfz-staging:
  stage: build
  extends: .docker_build
  script:
    - |
        docker build --tag "$CI_REGISTRY_IMAGE/mc:gfz-latest" -f docker/build/mc/gfz/Dockerfile \
          docker/build/mc/gfz
    - docker push "$CI_REGISTRY_IMAGE/mc:gfz-latest"
  rules:
    - if: '$CI_PIPELINE_SOURCE == "schedule"'
      when: never
    - if: '$CI_PIPELINE_SOURCE == "pipeline"'
      when: never
    - if: '$CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH'
      when: always

build-deploy-image-mc-gfz-prod:
  stage: build
  extends: .docker_build
  script:
    - |
        docker build \
          --tag "$CI_REGISTRY_IMAGE/mc:gfz-${CI_COMMIT_TAG}" \
          --tag "$CI_REGISTRY_IMAGE/mc:gfz-prod-latest" \
          -f docker/build/mc/gfz/Dockerfile \
          docker/build/mc/gfz
    - docker push "$CI_REGISTRY_IMAGE/mc:gfz-${CI_COMMIT_TAG}"
    - docker push "$CI_REGISTRY_IMAGE/mc:gfz-prod-latest"
  rules:
    - if: '$CI_PIPELINE_SOURCE == "schedule"'
      when: never
    - if: '$CI_COMMIT_REF_PROTECTED && $CI_COMMIT_TAG'
      when: always

backup-gfz-staging:
  stage: backup
  environment:
    name: gfz-staging
    url: https://rz-vm64.gfz-potsdam.de
  tags:
    - deploy
    - staging
    - gfz
    - shell
  variables:
    COMPOSE_PROJECT_NAME: sms-staging
    VOCABULARY_IMAGE: ${CI_REGISTRY_IMAGE}/vocabulary:gfz-latest
    VOCABULARY_SECRET_KEY: ${GFZ_STAGING_VOCABULARY_SECRET}
    VOCABULARY_DB_USER: ${GFZ_STAGING_VOCABULARY_POSTGRES_USER}
    VOCABULARY_DB_PASSWORD: ${GFZ_STAGING_VOCABULARY_POSTGRES_PASSWORD}
    IDL_DB_USER: ${GFZ_STAGING_IDL_POSTGRES_USER}
    IDL_DB_PASSWORD: ${GFZ_STAGING_IDL_POSTGRES_PASSWORD}
    IDL_TOKEN: ${GFZ_STAGING_IDL_TOKEN}
    MINIO_ROOT_USER: ${GFZ_STAGING_MINIO_ROOT_USER}
    MINIO_ROOT_PASSWORD: ${GFZ_STAGING_MINIO_ROOT_PASSWORD}
    BACKEND_IMAGE: ${CI_REGISTRY_IMAGE}/backend:gfz-latest
    BACKEND_DB_USER: ${GFZ_STAGING_BACKEND_POSTGRES_USER}
    BACKEND_DB_PASSWORD: ${GFZ_STAGING_BACKEND_POSTGRES_PASSWORD}
    BACKEND_SECRET_KEY: ${GFZ_STAGING_BACKEND_SECRET}
    OIDC_CLIENT_ID: ${GFZ_STAGING_OIDC_CLIENT_ID}
    DAYS_TO_CLEANUP: 30
    # We want to make sure that we still have 1 GB left to do the backup
    # comparision value is in kb
    MINIMUM_STORAGE_LEFT: 1000000
  before_script:
    - *docker_login_gitlab_registry
  script:
    # clean up & remove files older than x days
    - find /srv/docker/service/backend-db/backups -type f -mtime +${DAYS_TO_CLEANUP:-30} -exec rm {} \;
    - find /srv/docker/service/vocabulary-db/backups -type f -mtime +${DAYS_TO_CLEANUP:-30} -exec rm {} \;
    - find /srv/docker/service/idl-db/backups -type f -mtime +${DAYS_TO_CLEANUP:-30} -exec rm {} \;
    - find /srv/docker/service/minio/backups -type f -mtime +${DAYS_TO_CLEANUP:-30} -exec rm {} \;
    - |-
      if [ $(df -Pk /srv/docker/service | awk '/[0-9]%/{print $(NF-2)}') -lt ${MINIMUM_STORAGE_LEFT} ]
      then
          echo 'Not enough space left on the local file system to create the backup'
          exit 1
      fi
    - docker-compose -f docker/deployment/gfz/staging/docker-compose.yml pull mc
    - docker-compose -f docker/deployment/gfz/staging/docker-compose.yml exec -T vocabulary-db pg_dump -U $VOCABULARY_DB_USER -d vocabulary -Fc > /srv/docker/service/vocabulary-db/backups/vocabulary_$(date +%Y%m%d-%H%M)_${CI_COMMIT_SHORT_SHA}.dump
    - docker-compose -f docker/deployment/gfz/staging/docker-compose.yml exec -T idl-db pg_dump -U $IDL_DB_USER -d idl -Fc > /srv/docker/service/idl-db/backups/idl_$(date +%Y%m%d-%H%M)_${CI_COMMIT_SHORT_SHA}.dump
    - docker-compose -f docker/deployment/gfz/staging/docker-compose.yml exec -T backend-db pg_dump -U $BACKEND_DB_USER -d backend -Fc > /srv/docker/service/backend-db/backups/backend_$(date +%Y%m%d-%H%M)_${CI_COMMIT_SHORT_SHA}.dump
    # Most of the minio stuff is handled in the backup.sh script.
    # However, there are some things to mention:
    # First the mc image was already used to create the bucket. It is very likely that it is
    # already stopped, so we use docker-compose run here.
    # Next: We will mount our backup folder into the container in order to write the backup right
    # into there. We will give the current user & group ids, so that we can edit and delete
    # the backups content right away.
    - >
      docker-compose -f docker/deployment/gfz/staging/docker-compose.yml \
        run -T --entrypoint '/backup.sh' \
        --rm \
        -e USER_ID=$(id -u) \
        -e GROUP_ID=$(id -g) \
        -v /srv/docker/service/minio/backups/$(date +%Y%m%d-%H%M)_${CI_COMMIT_SHORT_SHA}:/backups \
        mc
  rules:
    - if: '$CI_PIPELINE_SOURCE == "schedule"'
      when: never
    - if: '$CI_PIPELINE_SOURCE == "pipeline"'
      when: never
    - if: '$CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH'
      when: always

backup-gfz-prod:
  stage: backup
  environment:
    name: gfz-prod
    url: https://sensors.gfz-potsdam.de
  tags:
    - deploy
    - prod
    - gfz
    - shell
  variables:
    COMPOSE_PROJECT_NAME: sms-prod
    VOCABULARY_SECRET_KEY: ${GFZ_PROD_VOCABULARY_SECRET}
    VOCABULARY_DB_USER: ${GFZ_PROD_VOCABULARY_POSTGRES_USER}
    VOCABULARY_DB_PASSWORD: ${GFZ_PROD_VOCABULARY_POSTGRES_PASSWORD}
    MINIO_ROOT_USER: ${GFZ_PROD_MINIO_ROOT_USER}
    MINIO_ROOT_PASSWORD: ${GFZ_PROD_MINIO_ROOT_PASSWORD}
    BACKEND_DB_USER: ${GFZ_PROD_BACKEND_POSTGRES_USER}
    BACKEND_DB_PASSWORD: ${GFZ_PROD_BACKEND_POSTGRES_PASSWORD}
    BACKEND_SECRET_KEY: ${GFZ_PROD_BACKEND_SECRET}
    OIDC_CLIENT_ID: ${GFZ_PROD_OIDC_CLIENT_ID}
    DAYS_TO_CLEANUP: 30
    DAYS_TO_CLEANUP_PROJECTSHARE: 180
    # We want to make sure that we still have 1 GB left to do the backup
    # comparision value is in kb
    MINIMUM_STORAGE_LEFT: 1000000
  before_script:
    - *docker_login_gitlab_registry
  script:
    # clean up & remove files older than 30 days
    # Note: We store the files of the latest x days on the machine
    # itself. But we also store the files on the projectshare, where
    # we keep them for longer.
    - find /srv/docker/service/backend-db/backups -type f -mtime +${DAYS_TO_CLEANUP:-30} -exec rm {} \;
    - find /srv/docker/service/vocabulary-db/backups -type f -mtime +${DAYS_TO_CLEANUP:-30} -exec rm {} \;
    - find /srv/docker/service/minio/backups -type f -mtime +${DAYS_TO_CLEANUP:-30} -exec rm {} \;
    - |-
      if [ $(df -Pk /srv/docker/service | awk '/[0-9]%/{print $(NF-2)}') -lt ${MINIMUM_STORAGE_LEFT} ]
      then
          echo 'Not enough space left on the local file system to create the backup'
          exit 1
      fi
    - docker-compose -f docker/deployment/gfz/prod/docker-compose.yml pull mc
    - docker-compose -f docker/deployment/gfz/prod/docker-compose.yml exec -T vocabulary-db pg_dump -U $VOCABULARY_DB_USER -d vocabulary -Fc > /srv/docker/service/vocabulary-db/backups/vocabulary_$(date +%Y%m%d-%H%M)_${CI_COMMIT_SHORT_SHA}.dump
    - docker-compose -f docker/deployment/gfz/prod/docker-compose.yml exec -T backend-db pg_dump -U $BACKEND_DB_USER -d backend -Fc > /srv/docker/service/backend-db/backups/backend_$(date +%Y%m%d-%H%M)_${CI_COMMIT_SHORT_SHA}.dump
    - >
      docker-compose -f docker/deployment/gfz/prod/docker-compose.yml \
        run -T --entrypoint '/backup.sh' \
        --rm \
        -e USER_ID=$(id -u) \
        -e GROUP_ID=$(id -g) \
        -v /srv/docker/service/minio/backups/$(date +%Y%m%d-%H%M)_${CI_COMMIT_SHORT_SHA}:/backups \
        mc
    - >
      docker-compose -f docker/deployment/gfz/prod/docker-compose.yml \
        run -T --entrypoint '/projectshare.sh' \
        --rm \
        -e CLEANUP=${DAYS_TO_CLEANUP_PROJECTSHARE:-180} \
        -u "$(id -u smsbckp):$(id -g sms-backup-rw)" \
        -v /srv/docker/service:/srv/docker/service:ro \
        -v /mnt/sms-backup:/mnt/sms-backup \
        mc
  rules:
    - if: '$CI_PIPELINE_SOURCE == "schedule"'
      when: always
    - if: '$CI_PIPELINE_SOURCE == "pipeline"'
      when: never
    - if: '$CI_COMMIT_REF_PROTECTED && $CI_COMMIT_TAG'
      when: always

deploy-gfz-staging:
  stage: deploy
  environment:
    name: gfz-staging
    url: https://rz-vm64.gfz-potsdam.de
  tags:
    - deploy
    - staging
    - gfz
    - shell
  variables:
    COMPOSE_PROJECT_NAME: sms-staging
    VOCABULARY_IMAGE: ${CI_REGISTRY_IMAGE}/vocabulary:gfz-latest
    VOCABULARY_SECRET_KEY: ${GFZ_STAGING_VOCABULARY_SECRET}
    VOCABULARY_DB_USER: ${GFZ_STAGING_VOCABULARY_POSTGRES_USER}
    VOCABULARY_DB_PASSWORD: ${GFZ_STAGING_VOCABULARY_POSTGRES_PASSWORD}
    IDL_DB_USER: ${GFZ_STAGING_IDL_POSTGRES_USER}
    IDL_DB_PASSWORD: ${GFZ_STAGING_IDL_POSTGRES_PASSWORD}
    IDL_TOKEN: ${GFZ_STAGING_IDL_TOKEN}
    MINIO_ROOT_USER: ${GFZ_STAGING_MINIO_ROOT_USER}
    MINIO_ROOT_PASSWORD: ${GFZ_STAGING_MINIO_ROOT_PASSWORD}
    BACKEND_IMAGE: ${CI_REGISTRY_IMAGE}/backend:gfz-latest
    BACKEND_DB_USER: ${GFZ_STAGING_BACKEND_POSTGRES_USER}
    BACKEND_DB_PASSWORD: ${GFZ_STAGING_BACKEND_POSTGRES_PASSWORD}
    BACKEND_SECRET_KEY: ${GFZ_STAGING_BACKEND_SECRET}
    OIDC_CLIENT_ID: ${GFZ_STAGING_OIDC_CLIENT_ID}
  before_script:
    - *docker_login_gitlab_registry
  script:
    - docker-compose -f docker/deployment/gfz/staging/docker-compose.yml down --remove-orphans
    - docker-compose -f docker/deployment/gfz/staging/docker-compose.yml rm -f
    - docker-compose -f docker/deployment/gfz/staging/docker-compose.yml pull
    - docker-compose -f docker/deployment/gfz/staging/docker-compose.yml up -d
    - docker-compose -f docker/deployment/gfz/staging/docker-compose.yml exec -T vocabulary python3 manage.py migrate
    - docker-compose -f docker/deployment/gfz/staging/docker-compose.yml exec -T vocabulary python3 manage.py loaddata initial_data.json
    - docker-compose -f docker/deployment/gfz/staging/docker-compose.yml exec -T vocabulary python3 manage.py loaddata default_community_data.json
    - docker-compose -f docker/deployment/gfz/staging/docker-compose.yml exec -T vocabulary python3 manage.py loaddata hydro_community_data.json
    - docker-compose -f docker/deployment/gfz/staging/docker-compose.yml exec -T vocabulary python3 manage.py collectstatic --no-input
    - docker-compose -f docker/deployment/gfz/staging/docker-compose.yml exec -T backend python3 manage.py db upgrade
    - sleep 1m
    - docker-compose -f docker/deployment/gfz/staging/docker-compose.yml exec -T backend python3 manage.py es reindex
    - docker rmi $(docker images -q -f dangling=true) || true
  rules:
    - if: '$CI_PIPELINE_SOURCE == "schedule"'
      when: never
    - if: '$CI_PIPELINE_SOURCE == "pipeline"'
      when: never
    - if: '$CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH'
      when: always

deploy-gfz-staging-develop:
  stage: deploy
  environment:
    name: gfz-staging
    url: https://rz-vm64.gfz-potsdam.de
  tags:
    - deploy
    - staging
    - gfz
    - shell
  variables:
    COMPOSE_PROJECT_NAME: sms-staging-develop
    VOCABULARY_IMAGE: $CI_REGISTRY/hub-terra/sms/sms-cv:gfz-latest
    VOCABULARY_SECRET_KEY: ${GFZ_STAGING_VOCABULARY_SECRET}
    VOCABULARY_DB_USER: ${GFZ_STAGING_VOCABULARY_POSTGRES_USER}
    VOCABULARY_DB_PASSWORD: ${GFZ_STAGING_VOCABULARY_POSTGRES_PASSWORD}
    IDL_DB_USER: ${GFZ_STAGING_IDL_POSTGRES_USER}
    IDL_DB_PASSWORD: ${GFZ_STAGING_IDL_POSTGRES_PASSWORD}
    IDL_TOKEN: ${GFZ_STAGING_IDL_TOKEN}
    CORS_ORIGIN_WHITELIST: "https://rz-vm64.gfz-potsdam.de localhost"
    MINIO_ROOT_USER: ${GFZ_STAGING_MINIO_ROOT_USER}
    MINIO_ROOT_PASSWORD: ${GFZ_STAGING_MINIO_ROOT_PASSWORD}
    BACKEND_IMAGE: $CI_REGISTRY/hub-terra/sms/backend:gfz-latest
    BACKEND_DB_USER: ${GFZ_STAGING_BACKEND_POSTGRES_USER}
    BACKEND_DB_PASSWORD: ${GFZ_STAGING_BACKEND_POSTGRES_PASSWORD}
    BACKEND_SECRET_KEY: ${GFZ_STAGING_BACKEND_SECRET}
    HTTP_ORIGINS: ${GFZ_STAGING_HTTP_ORIGINS}
    HTTP_ORIGINS_VOCABULARY: ${GFZ_STAGING_HTTP_ORIGINS_VOCABULARY}
    # App-settings need to be development to enable multiple client IDs
    APP_SETTINGS: "project.config.DevelopmentConfig"
    OIDC_CLIENT_IDS: ${GFZ_STAGING_DEVELOP_OIDC_CLIENT_IDS}
    NGINX_IMAGE_TAG: gfz-latest-develop
    APPLICATION_PORTS: 3000-3001
    MINIO_PORT: 3002
  before_script:
    - *docker_login_gitlab_registry
  script:
    - ./scripts/ensure_vm_max_map_count.sh
    - docker-compose -f docker/deployment/gfz/staging-dev/docker-compose.yml down --remove-orphans
    - docker-compose -f docker/deployment/gfz/staging-dev/docker-compose.yml rm -f
    - docker-compose -f docker/deployment/gfz/staging-dev/docker-compose.yml pull
    - docker-compose -f docker/deployment/gfz/staging-dev/docker-compose.yml up -d
    - docker-compose -f docker/deployment/gfz/staging-dev/docker-compose.yml exec -T vocabulary python3 manage.py migrate
    - docker-compose -f docker/deployment/gfz/staging-dev/docker-compose.yml exec -T vocabulary python3 manage.py loaddata initial_data.json
    - docker-compose -f docker/deployment/gfz/staging-dev/docker-compose.yml exec -T vocabulary python3 manage.py loaddata default_community_data.json
    - docker-compose -f docker/deployment/gfz/staging-dev/docker-compose.yml exec -T vocabulary python3 manage.py loaddata hydro_community_data.json
    - docker-compose -f docker/deployment/gfz/staging-dev/docker-compose.yml exec -T vocabulary python3 manage.py collectstatic --no-input
    - docker-compose -f docker/deployment/gfz/staging-dev/docker-compose.yml exec -T backend python3 manage.py db upgrade
    - sleep 1m
    - docker-compose -f docker/deployment/gfz/staging-dev/docker-compose.yml exec -T backend python3 manage.py es reindex
    - docker rmi $(docker images -q -f dangling=true) || true
  rules:
    - if: '$CI_PIPELINE_SOURCE == "schedule"'
      when: never
    # Exclude pipeline source, to prohibit triggering the job twice
    - if: '$CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH && $CI_PIPELINE_SOURCE != "pipeline"'
    - if: '$CI_PIPELINE_SOURCE == "pipeline"'

deploy-gfz-prod:
  stage: deploy
  environment:
    name: gfz-prod
    url: https://sensors.gfz-potsdam.de
  tags:
    - deploy
    - prod
    - gfz
    - shell
  variables:
    COMPOSE_PROJECT_NAME: sms-prod
    VOCABULARY_SECRET_KEY: ${GFZ_PROD_VOCABULARY_SECRET}
    VOCABULARY_DB_USER: ${GFZ_PROD_VOCABULARY_POSTGRES_USER}
    VOCABULARY_DB_PASSWORD: ${GFZ_PROD_VOCABULARY_POSTGRES_PASSWORD}
    MINIO_ROOT_USER: ${GFZ_PROD_MINIO_ROOT_USER}
    MINIO_ROOT_PASSWORD: ${GFZ_PROD_MINIO_ROOT_PASSWORD}
    BACKEND_DB_USER: ${GFZ_PROD_BACKEND_POSTGRES_USER}
    BACKEND_DB_PASSWORD: ${GFZ_PROD_BACKEND_POSTGRES_PASSWORD}
    BACKEND_SECRET_KEY: ${GFZ_PROD_BACKEND_SECRET}
    OIDC_CLIENT_ID: ${GFZ_PROD_OIDC_CLIENT_ID}
  before_script:
    - *docker_login_gitlab_registry
  script:
    - docker-compose -f docker/deployment/gfz/prod/docker-compose.yml down --remove-orphans
    - docker-compose -f docker/deployment/gfz/prod/docker-compose.yml rm -f
    - docker-compose -f docker/deployment/gfz/prod/docker-compose.yml pull
    - docker-compose -f docker/deployment/gfz/prod/docker-compose.yml up -d
    - docker-compose -f docker/deployment/gfz/prod/docker-compose.yml exec -T vocabulary python3 manage.py migrate
    - docker-compose -f docker/deployment/gfz/prod/docker-compose.yml exec -T vocabulary python3 manage.py loaddata initial_data.json
    - docker-compose -f docker/deployment/gfz/prod/docker-compose.yml exec -T vocabulary python3 manage.py loaddata default_community_data.json
    - docker-compose -f docker/deployment/gfz/prod/docker-compose.yml exec -T vocabulary python3 manage.py loaddata hydro_community_data.json
    - docker-compose -f docker/deployment/gfz/prod/docker-compose.yml exec -T vocabulary python3 manage.py collectstatic --no-input
    - docker-compose -f docker/deployment/gfz/prod/docker-compose.yml exec -T backend python3 manage.py db upgrade
    - sleep 1m
    - docker-compose -f docker/deployment/gfz/prod/docker-compose.yml exec -T backend python3 manage.py es reindex
    - docker rmi $(docker images -q -f dangling=true) || true
  rules:
    - if: '$CI_PIPELINE_SOURCE == "schedule"'
      when: never
    - if: '$CI_PIPELINE_SOURCE == "pipeline"'
      when: never
    - if: '$CI_COMMIT_REF_PROTECTED && $CI_COMMIT_TAG'
      when: always
